{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// You have to document your development of your grammars\n",
    "\n",
    "// 10 points for your documentation of work in the Python notebook assigned by the TAs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group members contribution:\n",
    "    \n",
    "  Algorithm designer: Enwei Zhou\n",
    "  \n",
    "  Algorithm implementor: Xiaofeng Zhuang , Enwei Zhou, Zhengjun Huang\n",
    "  \n",
    "  Data collection and classification: Zhengjun Huang\n",
    "  \n",
    "  Optimization: Enwei Zhou, Xiaofeng Zhuang, Zhengjun Huang\n",
    "  \n",
    "  Inferring Pos tag: Xiaofeng Zhuang , Xiaohan Cao , Zhengjun Huang , Enwei Zhou , Qifan Wu\n",
    "  \n",
    "  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S1.gr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Initially, we wrote grammars according to the knowledge of Linguistic because we have two members who have taken Linguistic course before. It works perfectly when we follow the rules of linguistic for the example_sentences.txt, but it does not work well for the devset.txt so we infer there are some rules we missed. We turn to observe and investigate the pase trees in the deveset_tree.txt. We decided use the devset_tree.txt as our sample and and write design rules according the to grammars in the devset_tree.txt. \n",
    "    The first step was converting the parse trees in the form of CFG. We put all the nodes of a tree into a list including the brackets, and do some list operation to convert to the form of CFG.  \n",
    "    We also counted how many times each rule has been used.  \n",
    "    We put those CNF and the counts in the devset_rule_counts.txt.  \n",
    "    After we got the devset_rule_counts.txt, we convert those rules in the devset_trees in the form of eCNF. The algrithm we use to convert is :\n",
    "        1. If right handside has more than two symbols, we merge the rule in order to keep the right handside to be   eCNF:\n",
    "            e.g:\n",
    "            the rules in the devset_rul_counts:\n",
    "                A -> B C D E\n",
    "            will be convert into:\n",
    "                A -> B CDE\n",
    "                CDE -> C DE\n",
    "                DE -> D E\n",
    "         2. To be consistent, Punctuation will be always merged to the right child. This is because, in this way, we can maximize the depth of the right subtree. \n",
    "                e.g:\n",
    "                A -> A PUNC B C will be convert to:\n",
    "                A -> A PUNCBC\n",
    "                PUNCBC -> PUNC BC\n",
    "                BC -> B C\n",
    "          \n",
    "         \n",
    "                \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2.gr\n",
    "\n",
    "`Using brute force method`\n",
    "\n",
    "We found that there are `36` Peen treebank POS tag for English words.\n",
    "We ended up using `37` tags in order to include punctuation.\n",
    "\n",
    "The way how S2 works is:\n",
    "\n",
    "    S2 can go to all tags and each tags can go all the other tags. \n",
    "\n",
    "e.g.<br>\n",
    "S2 -> _tag1<br>\n",
    "S2 -> _tag2<br>\n",
    "...\n",
    "\n",
    "_tag1 -> tag1  \n",
    "_tag1 -> tag1 _tag1  \n",
    "_tag1 -> tag1 _tag2<br>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first tried to use some external tools like Stanford Pos Tagger to tag the word.  \n",
    "\n",
    "However, all taggers we tried can only tag a word with one tag. For example, the word `\"end\"` is tagged to noun, but it can also be parsed as verb. Because of this, we were not able to parse some sample sentences. \n",
    "\n",
    "To solve this problem, we tried\n",
    "\n",
    "`Adding rules for words that have multiple meanings by hand`\n",
    "\n",
    "We splited the words in allow_words.txt evenly to each memebers.\n",
    "\n",
    "1/5 each person\n",
    "\n",
    "\n",
    "look up devset tree bank word's tag if some sentence can not be parsed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
